{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPlrVjzkz7SnZOWX6H9bsi/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanglic/idal_ia3_uv/blob/main/Transfer_Learning_Edificios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caeUBO0oL4js"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.applications.vgg16 import preprocess_input\r\n",
        "from keras.layers import Input, Flatten, Dense\r\n",
        "from keras.models import Model\r\n",
        "import numpy as np\r\n",
        "from glob import glob\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\n",
        "from keras.models import Sequential, load_model, Model\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\r\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\r\n",
        "from keras import backend as K\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras import regularizers\r\n",
        "from glob import glob\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from IPython.display import SVG, display, clear_output\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX_PX5vlQnZL"
      },
      "source": [
        "COLAB = True\r\n",
        "if COLAB:\r\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\r\n",
        "    gdd.download_file_from_google_drive(file_id='1cc5JyQvS4jJard7YsFKrYnHEcal0Bl6x',\r\n",
        "                                        dest_path='./seg_train.zip', unzip=True)\r\n",
        "    gdd.download_file_from_google_drive(file_id='1Gv5x1Y6K4JVLambfMBwGbDUDTC0xSQ2r',\r\n",
        "                                        dest_path='./seg_test.zip', unzip=True)\r\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQAYpDi7Qrlj"
      },
      "source": [
        "ficheros = glob(\"./seg_train/buildings/*\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efwn7bTRQuwz"
      },
      "source": [
        "train_data_dir = 'seg_train'\r\n",
        "validation_data_dir = 'seg_test'\r\n",
        "test_data_dir = 'seg_test'\r\n",
        "\r\n",
        "batch_size = 32"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T0t43-eTkzr"
      },
      "source": [
        "img_width, img_height = 150, 150\r\n",
        "\r\n",
        "normed_dims = (img_height, img_width)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEJfqF-XROdr"
      },
      "source": [
        "# data augmentation:\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1. / 255,\r\n",
        "    rotation_range=20,\r\n",
        "    width_shift_range=0.1,\r\n",
        "    height_shift_range=0.1,\r\n",
        "    fill_mode='nearest',\r\n",
        "    shear_range=0.1,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True)\r\n",
        "\r\n",
        "test_datagen= ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMllD7qyRT0k"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\r\n",
        "    dtype='float32',\r\n",
        "    preprocessing_function = preprocess_input,\r\n",
        "    rotation_range=40,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    fill_mode='nearest',\r\n",
        "    shear_range=0.2,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True)\r\n",
        "\r\n",
        "val_datagen  = ImageDataGenerator(dtype='float32',\r\n",
        "                                  preprocessing_function = preprocess_input)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(dtype='float32',\r\n",
        "                                  preprocessing_function = preprocess_input)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vz2pZx_Rd0j",
        "outputId": "5a210d25-4ac3-4d88-8f49-01a9327ed0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    train_data_dir,\r\n",
        "    target_size=normed_dims,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "validation_generator = val_datagen.flow_from_directory(\r\n",
        "    validation_data_dir,\r\n",
        "    target_size=normed_dims,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(\r\n",
        "    test_data_dir,\r\n",
        "    target_size=normed_dims,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode='sparse')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14034 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvuPryMrMDgO",
        "outputId": "d2f31ed1-7370-4af2-aa48-d5afa99d2ad2"
      },
      "source": [
        "#Get back the convolutional part of a VGG network trained on ImageNet\r\n",
        "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\r\n",
        "for layer in model_vgg16_conv.layers:\r\n",
        "\t\t\tlayer.trainable = False\r\n",
        "model_vgg16_conv.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfTX9kSiMPjL"
      },
      "source": [
        "#Create your own input format (here 3x150x150)\r\n",
        "Keras_input = Input(shape=(150,150,3),name = 'seg_train')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLFliC9CMgPc"
      },
      "source": [
        "#Use the generated model \r\n",
        "output_vgg16_conv = model_vgg16_conv(Keras_input)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHGyIQVbMgcc"
      },
      "source": [
        "#Add the fully-connected layers \r\n",
        "x = Flatten(name='flatten')(output_vgg16_conv)\r\n",
        "x = Dense(4096, activation='relu', name='fc1')(x)\r\n",
        "x = Dense(4096, activation='relu', name='fc2')(x)\r\n",
        "x = Dense(6, activation='softmax', name='predictions')(x)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDR0N8TiQY4l"
      },
      "source": [
        "#Create your own model \r\n",
        "my_model = Model(inputs=Keras_input, outputs=x)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c6eqsAFQauD",
        "outputId": "5774419c-3047-4b4e-b832-78cec4a19f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\r\n",
        "my_model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seg_train (InputLayer)       [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              33558528  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 6)                 24582     \n",
            "=================================================================\n",
            "Total params: 65,079,110\n",
            "Trainable params: 50,364,422\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5mShsiWXR56"
      },
      "source": [
        "my_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49wWIOFrXa8S"
      },
      "source": [
        "from matplotlib.ticker import MaxNLocator\r\n",
        "\r\n",
        "def grafica_entrenamiento(tr_acc, val_acc, tr_loss, val_loss, best_i,\r\n",
        "                          figsize=(10,4)):\r\n",
        "    plt.figure(figsize=figsize)\r\n",
        "    ax = plt.subplot(1,2,1)\r\n",
        "    plt.plot(1+np.arange(len(tr_acc)),  100*np.array(tr_acc))\r\n",
        "    plt.plot(1+np.arange(len(val_acc)), 100*np.array(val_acc))\r\n",
        "    plt.plot(1+best_i, 100*val_acc[best_i], 'or')\r\n",
        "    plt.title('tasa de acierto del modelo (%)', fontsize=18)\r\n",
        "    plt.ylabel('tasa de acierto (%)', fontsize=18)\r\n",
        "    plt.xlabel('época', fontsize=18)\r\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\r\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "\r\n",
        "    plt.subplot(1,2,2)\r\n",
        "    plt.plot(1+np.arange(len(tr_acc)), np.array(tr_loss))\r\n",
        "    plt.plot(1+np.arange(len(val_acc)), np.array(val_loss))\r\n",
        "    plt.plot(1+best_i, val_loss[best_i], 'or')\r\n",
        "    plt.title('loss del modelo', fontsize=18)\r\n",
        "    plt.ylabel('loss', fontsize=18)\r\n",
        "    plt.xlabel('época', fontsize=18)\r\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\r\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\r\n",
        "    plt.show()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6cIHaoBXoIy"
      },
      "source": [
        "acum_tr_acc = []\r\n",
        "acum_val_acc = []\r\n",
        "best_val_acc = -1000\r\n",
        "acum_tr_loss  = []\r\n",
        "acum_val_loss = []"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBP7Pn9CYA6B"
      },
      "source": [
        "number_train_samples = train_generator.n\r\n",
        "number_val_samples   = validation_generator.n\r\n",
        "number_test_samples  = test_generator.n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyed18BHbbF8"
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVG9QJttXskp",
        "outputId": "7232e774-af43-41a9-d74a-281612dc226a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 1\r\n",
        "\r\n",
        "modelpath=\"best_model.h5\"\r\n",
        "\r\n",
        "checkpoint = ModelCheckpoint(modelpath, monitor='val_accuracy', verbose=1,\r\n",
        "                              save_best_only=True,\r\n",
        "                              mode='max') # graba sólo los que mejoran en validación\r\n",
        "callbacks_list = [checkpoint]\r\n",
        "for e in range(epochs):\r\n",
        "    history = my_model.fit_generator(generator = train_generator, \r\n",
        "                                  steps_per_epoch=number_train_samples // batch_size,\r\n",
        "                                  epochs=1,\r\n",
        "                                  callbacks=callbacks_list,\r\n",
        "                                  verbose=1,\r\n",
        "                                  shuffle = True,\r\n",
        "                                  validation_data=validation_generator,\r\n",
        "                                  validation_steps=number_val_samples // batch_size\r\n",
        "                                  )\r\n",
        "    \r\n",
        "    if history.history['val_accuracy'][-1] > best_val_acc:\r\n",
        "        print(\"Validation accuracy improved from\",\r\n",
        "            best_val_acc, 'to', history.history['val_accuracy'])\r\n",
        "        print(\"saving weights\")\r\n",
        "        best_val_acc = history.history['val_accuracy'][-1]\r\n",
        "    \r\n",
        "    acum_tr_acc.append(history.history['accuracy'][0])\r\n",
        "    acum_val_acc.append(history.history['val_accuracy'][0])\r\n",
        "    acum_tr_loss.append(history.history['loss'][0])\r\n",
        "    acum_val_loss.append(history.history['val_loss'][0])\r\n",
        "    \r\n",
        "    if len(acum_tr_acc) > 1:\r\n",
        "        clear_output()\r\n",
        "        best_i = np.argmax(acum_val_acc)\r\n",
        "        grafica_entrenamiento(acum_tr_acc, acum_val_acc, acum_tr_loss, acum_val_loss, best_i)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "438/438 [==============================] - 91s 206ms/step - loss: 8.1362 - accuracy: 0.7456 - val_loss: 0.3795 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.88004, saving model to best_model.h5\n",
            "Validation accuracy improved from -1000 to [0.8800403475761414]\n",
            "saving weights\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}